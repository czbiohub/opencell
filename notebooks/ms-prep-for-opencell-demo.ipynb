{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing mass spec data for the open-cell website demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as mpl_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'original' dataset for the demo\n",
    "filepath = '../data/mass-spec/2019-08-02_volcano_plots_all.txt'\n",
    "d1 = pd.read_csv(filepath, sep='\\t')\n",
    "\n",
    "# a second dataset for the demo\n",
    "filepath = '../data/mass-spec/MS_052319.csv'\n",
    "d2 = pd.read_csv(filepath, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK: manually drop 'ATP2B1' and 'POLR1C', which appear in both datasets\n",
    "d1 = d1.drop([\n",
    "    'LFQi 1_ATP2B1: -Log(P-value)', \n",
    "    'LFQi 1_POLR1C: -Log(P-value)', \n",
    "    'LFQi 1_ATP2B1: Difference',\n",
    "    'LFQi 1_POLR1C: Difference',\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(d):\n",
    "    d.rename(columns={col: col.lower().replace(' ', '_') for col in d.columns}, inplace=True)\n",
    "    d.rename(columns={'Gene names': 'gene_names', 'Protein names': 'protein_names'}, inplace=True)\n",
    "    \n",
    "cleanup(d1)\n",
    "cleanup(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on gene names column \n",
    "# (a bit sketchy because this requires the list of gene names to be identical)\n",
    "d = pd.merge(d1, d2, how='outer', on='gene_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.shape, d2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.shape[0] + d2.shape[0], d.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually merge the protein_names column\n",
    "mk = d['protein_names_y'].isna()\n",
    "d.loc[mk, 'protein_names_y'] = d.loc[mk, 'protein_names_x']\n",
    "\n",
    "mk = d['protein_names_x'].isna()\n",
    "d.loc[mk, 'protein_names_x'] = d.loc[mk, 'protein_names_y']\n",
    "\n",
    "d['protein_names'] = d['protein_names_x']\n",
    "d = d.drop(['protein_names_x', 'protein_names_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_columns = ['gene_names', 'protein_names']\n",
    "metadata = d[meta_columns].copy()\n",
    "\n",
    "# create a gene_name column with the first name in the list of gene_names in each row\n",
    "metadata['gene_name'] = [str(s).split(';')[0] for s in metadata.gene_names]\n",
    "\n",
    "# minimal metadata ('protein_names' contains longer descriptive names)\n",
    "metadata = metadata[['gene_name', 'gene_names', 'protein_names']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column name patterns (common between the two MS datasets)\n",
    "pvalue_pattern = r'^lfq.+_(\\w+):_-log\\(p-value\\)$'\n",
    "enrichment_pattern = r'^lfq.+_(\\w+):_difference$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes of pvalues and enrichments with columns names equal to gene_name\n",
    "pvalue_columns = [col for col in d.columns if re.findall(pvalue_pattern, col)]\n",
    "enrichment_columns = [col for col in d.columns if re.findall(enrichment_pattern, col)]\n",
    "\n",
    "pvalues = d[pvalue_columns].copy()\n",
    "enrichments = d[enrichment_columns].copy()\n",
    "\n",
    "pvalues.rename(columns={\n",
    "    col: re.findall(pvalue_pattern, col)[0] for col in pvalues.columns}, inplace=True)\n",
    "\n",
    "enrichments.rename(columns={\n",
    "    col: re.findall(enrichment_pattern, col)[0] for col in enrichments.columns}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichments.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating FDR curve parameters\n",
    "This approach is an attempt to exactly implement the algorithm described in Hein 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fdr(x0, c):\n",
    "    '''\n",
    "    Calculate the false discovery rate (FDR) for a given x0 and c\n",
    "\n",
    "    The FDR is the number of negatively-enriched hits with p-values above the FDR curve, \n",
    "    relative to the total number of hits with p-values above the FDR curve\n",
    "    \n",
    "    The FDR curve itself is a function only of enrichment and is given by\n",
    "    c / (abs(enrichment) - x0)\n",
    "    '''\n",
    "    \n",
    "    all_en = enrichments.values\n",
    "    all_pval = pvalues.values\n",
    "    \n",
    "    pval_neg = all_pval[all_en < (-x0)]\n",
    "    en_neg = all_en[all_en < (-x0)]\n",
    "    num_neg = (pval_neg > (c / (-en_neg - x0))).sum()\n",
    "\n",
    "    pval_pos = all_pval[all_en > x0]\n",
    "    en_pos = all_en[all_en > x0]\n",
    "    num_pos = (pval_pos > (c / en_pos - x0)).sum()\n",
    "    \n",
    "    return num_neg, num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive grid search over x0 and c\n",
    "x0s, cs = np.meshgrid(np.arange(1.5, 5, .03), np.arange(1, 6, .03))\n",
    "\n",
    "fdrs = x0s * 0\n",
    "nums_true = x0s*0\n",
    "for i in range(fdrs.shape[0]):\n",
    "    for j in range(fdrs.shape[1]):\n",
    "        num_neg, num_pos = calc_fdr(x0s[i][j], cs[i][j])\n",
    "        fdrs[i][j] = num_neg / (num_neg + num_pos)\n",
    "        nums_true[i][j] = num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the parameters with an FDR near the given threshold (usually 0.01 or 0.05)\n",
    "thresh = 0.05\n",
    "wiggle = .001\n",
    "\n",
    "mask = (fdrs < (thresh + wiggle)) & (fdrs > (thresh - wiggle))\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the parameters with the greatest number of positive hits\n",
    "ind = np.argmax(nums_true[mask])\n",
    "x0s[mask][ind], cs[mask][ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the FDR curve \n",
    "x0, c = 1.62, 4.25\n",
    "\n",
    "x = np.arange(x0, 15, .1)\n",
    "plt.plot(x, c/(x - x0), color='gray')\n",
    "\n",
    "x = np.arange(-15, -x0, .1)\n",
    "plt.plot(x, c/(-x - x0), color='gray')\n",
    "\n",
    "plt.scatter(enrichments, pvalues, alpha=.1)\n",
    "plt.gca().set_ylim([0, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neg, num_pos = calc_fdr(x0, c)\n",
    "print('%d, %d, %0.4f' % (num_neg, num_pos, num_neg / (num_neg + num_pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct JSON data for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrichments and p-values for all targets\n",
    "ms_data = []\n",
    "for target_name in pvalues.columns:\n",
    "    \n",
    "    hits = []\n",
    "    ms_datum = {'target_name': target_name.upper()}\n",
    "    for ind, row in metadata.iterrows():\n",
    "        \n",
    "        hits.append({\n",
    "            'gene_id': ind,\n",
    "            'pvalue': '%0.2f' % pvalues[target_name].iloc[ind],\n",
    "            'enrichment': '%0.2f' % enrichments[target_name].iloc[ind],\n",
    "        })\n",
    "\n",
    "    ms_datum['hits'] = hits\n",
    "    ms_data.append(ms_datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.loc[metadata.gene_name.isin([row['target_name'] for row in ms_data])].sort_values(by='gene_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../src/demo/data/20190816_ms-data.json', 'w') as file:\n",
    "    json.dump(ms_data, file)\n",
    "    \n",
    "with open('../src/demo/data/20190816_ms-metadata.json', 'w') as file:\n",
    "    metadata.to_json(file, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facsenv",
   "language": "python",
   "name": "facsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
