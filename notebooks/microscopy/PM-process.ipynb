{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the 'PlateMicroscopy' directory\n",
    "__Fall 2019__<br>\n",
    "__Keith Cheveralls__\n",
    "\n",
    "This notebook documents the development of methods to process the raw TIFFs found in the 'PlateMicroscopy' directory. This directory contains all raw pipeline/opencell microscopy data up to PML0179; this data was acquired by Nathan/Preethi and used Nathan's automation scripts (these were either beanshell scripts or, later, mm2python-powered python scripts). It corresponds to all datasets for Plates 1-19 and for thawed Plates 1-5. This data was acquired between October 2018 and August 2019. \n",
    "\n",
    "It also includes analysis of the FOV scores for all of the FOVs in this directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import nrrd\n",
    "import shutil\n",
    "import pickle\n",
    "import hashlib\n",
    "import skimage\n",
    "import datetime\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import imageio\n",
    "import dask\n",
    "import dask.diagnostics\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.append('..')\n",
    "from opencell.database import models, operations\n",
    "from opencell.database import utils as db_utils\n",
    "\n",
    "sys.path.append('/Users/keith.cheveralls/projects/dragonfly-automation/')\n",
    "import dragonfly_automation.utils\n",
    "from dragonfly_automation.fov_models import PipelineFOVScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport opencell.imaging.processors\n",
    "%aimport opencell.imaging.managers\n",
    "%aimport opencell.imaging.images\n",
    "\n",
    "from opencell.imaging import images, utils, viz\n",
    "from opencell.imaging.managers import PlateMicroscopyManager\n",
    "from opencell.imaging.processors import FOVProcessor\n",
    "from opencell.imaging.images import RawPipelineTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESS 'PlateMicroscopy' directory\n",
    "ess_root = '/Volumes/ml_group/PlateMicroscopy/'\n",
    "os.path.isdir(ess_root)\n",
    "\n",
    "dst_root = '/Volumes/ml_group/opencell-microscopy/'\n",
    "os.path.isdir(dst_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing and processing all raw FOVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance of a PlateMicroscopy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = PlateMicroscopyManager(ess_root, '../plate-microscopy-cache/20191114-ess/')\n",
    "len(pm.os_walk), pm.md.shape[0], pm.md.is_raw.sum(), pm.md_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.md_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the metadata text files\n",
    "\n",
    "As far as I can tell, there's nothing in these text files (which are actually JSON files) that's not also in the IJMetadata and MicroManagerMetadata TIFF tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pm.src_filepath(d_raw.iloc[0]).replace('.ome.tif', '_metadata.txt'), 'r') as file:\n",
    "    d = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([(key, val) for key, val in d['FrameKey-0--1-0'].items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing raw TIFF metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = RawPipelineTIFF('/Users/keith.cheveralls/image-data/MMStack_0-B9-0.ome.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.parse_micromanager_metadata()\n",
    "t.validate_micromanager_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.split_channels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of metadata issues\n",
    "\n",
    "__Loading tiffs with `tifffile.TiffFile`__<br>\n",
    "The stand-alone tifffile package (v0.15.1) works to load all raw TIFFs. There are 14754 stacks in 'v1' metadata format and 5243 in 'v2' format.\n",
    "\n",
    "\n",
    "__Inconsistent number of slices per channel__\n",
    "- 'P0014_ML0118_E2_1_RPS6KA4_events' page 50 - last page missing tags and the GFP channel is missing completely\n",
    "- 'P0014_ML0120_H5_12_VRK3_events' page 76 - last page is missing tags and half of the GFP channel is missing\n",
    "- 'P0018_ML0132_F4_4_GOLT1B_events' page 192 - last page missing tags and uneven number of slices in DAPI and GFP\n",
    " \n",
    "__Inconsistent exposure times__<br>\n",
    "There are three TIFFs with inconsistent exposure times: 'G5_22_TRIM24.ome.tif', 'G12_13_ANLN.ome.tif', 'F9_9_JAK1.ome.tif'. In all cases, the exposure time from the GFP seems to have been prematurely assigned to some of the DAPI slices. TODO: determine whether this is true for the metadata or the actual acqusitions.  \n",
    "\n",
    "\n",
    "__Other issues__<br>\n",
    "- some raw TIFFs have a negative DAPI channel index (indices are -1 and 0 for DAPI and GFP)\n",
    "- some raw TIFFs have an extra page with no metadata or data\n",
    "- some raw TIFFs may have extra pages at the end, possibly with valid metadata (according to Nathan)\n",
    "\n",
    "__Missing metadata in disentangled stacks for Plate16,17,18__<br>\n",
    "The raw TIFFs from Plates 16,17,18 that were disentangled from 'giant' stacks in the `_compressed` subdirectories using Nathan's `stackDisentangle.py` script all have invalid MM metadata tags. Due to a bug, the MM metadata tag from the first page of the disentangled stack appears on every page. Retrieving the true MM metadata for each page will require re-disentangling the stacks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all parsing events and the parsed metadata\n",
    "\n",
    "Note that this is deprecated until we implement a new method to aggregate all of the processing-event CSVs (which are not inserted into the database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pd.read_csv(os.path.join(dst_root, 'aggregated-processing-events.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = ev.loc[ev.message.apply(lambda m: 'IJMetadata' not in m)]\n",
    "ev = ev.loc[ev.message.apply(lambda m: 'Inconsistent values' not in m)]\n",
    "ev.groupby(['plate_dir', 'message']).agg(['count', 'first'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('%s/aggregated-raw-tiff-metadata.csv' % dst_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(df.gfp_exposure_time, bins=np.arange(0, 400, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, edges = np.histogram(df.gfp_max_intensity, bins=np.arange(0, 65535, 100))\n",
    "plt.plot(edges[1:], (counts + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.gfp_exposure_time, df.gfp_max_intensity, alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.gfp_max_intensity==65535).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gfp_exposure_time.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring all raw FOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = PipelineFOVScorer(mode='training', model_type='regression')\n",
    "scorer.load('/Users/keith.cheveralls/projects/dragonfly-automation/models/2019-10-08/')\n",
    "scorer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for all raw FOVs from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = db_utils.url_from_credentials('../db-credentials-cap.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features and score for all FOVs from opencelldb\n",
    "result_kind = 'calculate_fov_features'\n",
    "with operations.session_scope(url) as session:\n",
    "    results = session.query(models.MicroscopyFOVResult)\\\n",
    "        .filter(models.MicroscopyFOVResult.method_name==result_kind).all()\n",
    "    dfeat = pd.DataFrame(\n",
    "        data=[{'line_id': row.fov.cell_line_id, 'fov_id': row.fov.id, **row.data} for row in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfeat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate FOV processors from opencelldb\n",
    "with operations.session_scope(url) as session:\n",
    "    fovs = session.query(models.MicroscopyFOV).all()\n",
    "    ps = [FOVProcessor.from_database(fov) for fov in fovs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct FOV metadata (fov_id, plate_id, well_id, imaging_round_id)\n",
    "rows = []\n",
    "for p in ps:\n",
    "    filepath = p.dst_filepath(\n",
    "        dst_root='/Volumes/ml_group/opencell-microscopy/', \n",
    "        kind='projection', \n",
    "        channel='dapi', \n",
    "        axis='z',\n",
    "        makedirs=False)\n",
    "\n",
    "    filepath = p.tag_filepath(filepath, tag='DAPI-PROJ-Z', ext='tif')\n",
    "    rows.append({\n",
    "        'fov_id': p.fov_id,\n",
    "        'filepath': filepath,\n",
    "        'plate_id': p.plate_id,\n",
    "        'well_id': p.well_id,\n",
    "        'imaging_round_id': p.imaging_round_id,\n",
    "        'target_name': p.target_name,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmeta = pd.DataFrame(data=rows)\n",
    "dmeta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge metadata and features on fov_id\n",
    "data = pd.merge(dmeta, dfeat, left_on='fov_id', right_on='fov_id', how='inner')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns used in plots below\n",
    "data['yp'] = data.score\n",
    "data['plate_num'] = [int(s[1:]) for s in data.plate_id]\n",
    "data['imaging_round_num'] = [int(s[1:]) for s in data.imaging_round_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(data.target_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of cell_lines without any score-able FOVs\n",
    "data.groupby('line_id').score.max().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a processor of one FOV\n",
    "p = [p for p in ps if p.fov_id==18000][0]\n",
    "p.dst_filepath('', kind='cropz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.crop_cell_layer('/Volumes/ml_group/PlateMicroscopy/', dst_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.generate_nrrd(dst_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for all raw FOVs from cached results CSVs\n",
    "\n",
    "This is after calculating features from the z-projections of all raw FOVs using the `imaging_tasks` CLI on `cap`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_md = pd.read_csv('/Volumes/ml_group/oc-plate-microscopy/aggregated-raw-tiff-metadata.csv')\n",
    "\n",
    "# patch fov_id ('ML0125-C11-4' -> 'ML0125-C11-S04') (change made on Fri 2019-11-15)\n",
    "all_md['fov_id'] = [\n",
    "    '-'.join(fov_id.split('-')[:-1] + ['S%02d' % int(fov_id.split('-')[-1])])\n",
    "    for fov_id in all_md.fov_id]\n",
    "all_md.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(all_md.fov_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.read_csv('/Volumes/ml_group/oc-plate-microscopy/aggregated-fov-features.csv')\n",
    "\n",
    "# patch fov_id ('ML0125-C11-4' -> 'ML0125-C11-S04') (change made on Fri 2019-11-15)\n",
    "all_features['fov_id'] = [\n",
    "    '-'.join(fov_id.split('-')[:-1] + ['S%02d' % int(fov_id.split('-')[-1])])\n",
    "    for fov_id in all_features.fov_id]\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data and metadata\n",
    "data = pd.merge(pm.md_raw.copy(), all_features, left_on='fov_id', right_on='fov_id', how='inner')\n",
    "data.rename(columns={'filename_x': 'src_filename', 'filename_y': 'dst_filename'}, inplace=True)\n",
    "data.shape, pm.md_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('error').count().is_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data.error.isna()]\n",
    "data.drop(labels='error', axis=1, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct filepaths to the DAPI z-projections\n",
    "def construct_filepath(filename, dst_root):\n",
    "    plate_dir = '-'.join(filename.split('-')[:4])\n",
    "    filepath = os.path.join(dst_root, plate_dir, filename)\n",
    "    return filepath\n",
    "\n",
    "dst_root = '/Users/keith.cheveralls/image-data/oc-plate-microscopy/projections/dapi/z'\n",
    "data['filepath'] = None\n",
    "for ind, row in data.iterrows():\n",
    "    data.at[ind, 'filepath'] = construct_filepath(row.dst_filename, dst_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force inf to nan because dropna does not drop np.infs\n",
    "data = data.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# drop FOVs with missing features\n",
    "data = data.dropna(axis=0, how='any', subset=scorer.feature_order)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted scores for unsorted FOVs\n",
    "X = data[list(scorer.feature_order)].values\n",
    "yp = scorer.model.predict(X)\n",
    "data['yp'] = yp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summaries and plots of FOV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic summary by well\n",
    "dg = data.groupby(['plate_id', 'well_id', 'target_name'])\n",
    "summary = pd.concat((dg.yp.max(), dg.yp.count()), axis=1)\n",
    "summary.columns = 'max_score', 'num_fovs'\n",
    "\n",
    "summary = summary.sort_values(by=['plate_id', 'max_score'])\n",
    "# summary.to_csv('/Users/keith.cheveralls/image-data/oc-plate-microscopy-max-scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of max score per target\n",
    "plt.hist(data.groupby('target_name').yp.max().values, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tile all FOVs, sorted by score, from a particular plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOVs from a particular plate with a particular score\n",
    "d = data.loc[(data.plate_num==8) & (data.imaging_round_num==1)].copy()\n",
    "d = d.sort_values(by='yp', ascending=False)\n",
    "d.shape, 25*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - manually verify that the target_names for the selected plate \n",
    "# match the 'mNG11 HEK Library' google sheet\n",
    "sorted(d.target_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check - manually verify the ML experiment IDs are correct\n",
    "sorted(d.exp_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = (d.yp < -.5)\n",
    "neutral = (d.yp > -.5) & (d.yp < .5)\n",
    "good = d.yp > .5\n",
    "alll = bad | neutral | good\n",
    "\n",
    "tile = viz.build_tile(\n",
    "    d.loc[alll], \n",
    "    shape=(30, 30), \n",
    "    figsize=25, \n",
    "    offset=0,\n",
    "    show_labels=True, \n",
    "    label_column='yp', \n",
    "    label_format='%0.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifffile.imsave('/Users/keith.cheveralls/image-data/all-raw-plate7-ordered-by-score-30x30.tif', tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tiles for all plates\n",
    "for plate_id in data.plate_id.unique():\n",
    "    print(plate_id)\n",
    "    d = data.loc[data.plate_id==plate_id].copy()\n",
    "    d = d.sort_values(by='yp', ascending=False)\n",
    "    tile = viz.build_tile(\n",
    "        d, \n",
    "        shape=(30, 30), \n",
    "        figsize=25, \n",
    "        offset=0,\n",
    "        plot=False)\n",
    "    tifffile.imsave('/Users/keith.cheveralls/image-data/FOV-tile-all-raw-plate%s-30x30.tif' % plate_id, tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms of scores per plate and imaging round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_round_nums = [(n, 1) for n in range(1, 21)] + [(n, 2) for n in range(1, 6)]\n",
    "\n",
    "bin_width = 0.2\n",
    "plot_neg = True\n",
    "if plot_neg:\n",
    "    bin_min = -1.0\n",
    "    ymax = 4\n",
    "else:\n",
    "    bin_min = -.8\n",
    "    ymax = 1.5\n",
    "\n",
    "n = 0\n",
    "fig, axs = plt.subplots(5, 5, figsize=(16, 12))\n",
    "for rind, row in enumerate(axs):\n",
    "    for cind, ax in enumerate(row):\n",
    "        plate_num, round_num = plate_round_nums[n]\n",
    "        n += 1\n",
    "        if plate_num > 19:\n",
    "            continue\n",
    "            \n",
    "        values = data.loc[(data.plate_num==plate_num) & (data.imaging_round_num==round_num)].yp.values\n",
    "        ax.hist(values, bins=np.arange(bin_min, 1 + bin_width, bin_width), density=True)\n",
    "        ax.set_title('Plate %s-%s (n = %d)' % (plate_num, round_num, len(values)))    \n",
    "\n",
    "        ax.set_ylim([0, ymax])\n",
    "        ax.set_xticks([-1, -.5, 0, .5, 1])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        if cind==0:\n",
    "            ax.set_ylabel('Density')\n",
    "            ax.set_yticklabels([0, 1, 2, 3])\n",
    "        if rind==len(axs)-1:\n",
    "            ax.set_xlabel('Score')\n",
    "            ax.set_xticklabels([-1, -.5, 0, .5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent good/bad FOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent good and bad scores per plate-round\n",
    "pbad, pgood = [], []\n",
    "for plate_round_num in plate_round_nums:\n",
    "    plate_num, round_num = plate_round_num\n",
    "    values = data.loc[(data.plate_num==plate_num) & (data.imaging_round_num==round_num)].yp.values\n",
    "    pgood.append((values > .7).sum() / len(values))\n",
    "    pbad.append((values < -.7).sum() / len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent good and bad *max* scores (by target_name), per plate-round\n",
    "pbad, pgood, pnan = [], [], []\n",
    "for plate_round_num in plate_round_nums:\n",
    "    plate_num, r_num = plate_round_num\n",
    "    values = data.loc[(data.plate_num==plate_num)].groupby('target_name').max().yp.values\n",
    "    pgood.append((values > .5).sum() / len(values))\n",
    "    pbad.append((values < -.5).sum() / len(values))\n",
    "    pnan.append(np.isnan(values).sum() / len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "width = 1/4\n",
    "\n",
    "x = np.arange(len(plate_round_nums))\n",
    "rects1 = ax.bar(x - width, np.array(pgood)*100, width, label='Predicted good')\n",
    "rects2 = ax.bar(x + 0*width, np.array(pbad)*100, width, label='Predicted bad')\n",
    "rects3 = ax.bar(x + width, np.array(pnan)*100, width, label='All NaN')\n",
    "\n",
    "ax.set_ylabel('Percent')\n",
    "ax.set_title('')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['%s-%s' % plate_round_num for plate_round_num in plate_round_nums])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recapitulate Nathan's stack disentangling script\n",
    "\n",
    "We see that TiffWriter.save does not actually save the MM metadata tag for each page; instead, it saves the MM tag from the first page with every subsequent page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = images.RawPipelineTIFF('/Users/keith.cheveralls/image-data/plate18-ex-compressed/MMStack_31.ome.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = images.RawPipelineTIFF('/Users/keith.cheveralls/image-data/plate17-ex-compressed/MMStack_0.ome.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.parse_micromanager_metadata()\n",
    "t.validate_micromanager_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t.mm_metadata.slice_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entangled_tiff = tifffile.TiffFile('/Users/keith.cheveralls/image-data/plate17-ex-compressed/MMStack_0.ome.tif')\n",
    "\n",
    "new_pages = []\n",
    "new_tags = []\n",
    "for ind in range(222):\n",
    "    page = entangled_tiff.pages[ind]\n",
    "    new_pages.append(page.asarray())\n",
    "    mm_metadata = json.dumps(page.tags['MicroManagerMetadata'].value)\n",
    "    mm_tag = ('MicroManagerMetadata', 's', 0, mm_metadata, False)\n",
    "    new_tags.append(mm_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_out = tifffile.TiffWriter('/Users/keith.cheveralls/image-data/plate17-ex-compressed/test-disentangle-first-222-pages.tif')\n",
    "for page, tag in zip(new_pages, new_tags):\n",
    "    t_out.save(page, extratags=[tag], contiguous=False)\n",
    "t_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = images.RawPipelineTIFF('/Users/keith.cheveralls/image-data/plate17-ex-compressed/test-disentangle-first-222-pages.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.parse_micromanager_metadata()\n",
    "t.validate_micromanager_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nathan's QC CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc14 = pd.concat([\n",
    "    pd.read_csv(f, header=None, names=['target', 'flag']) \n",
    "    for f in glob.glob('/Users/keith.cheveralls/Box/AutomatedImageQC/QCFiles/Plate14/*.csv')])\n",
    "\n",
    "qc15 = pd.concat([\n",
    "    pd.read_csv(f, header=None, names=['target', 'flag']) \n",
    "    for f in glob.glob('/Users/keith.cheveralls/Box/AutomatedImageQC/QCFiles/Plate15/*.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc14.loc[qc14.flag=='GoodStack'].shape, qc15.loc[qc15.flag=='GoodStack'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc14.shape, qc15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearnenv",
   "language": "python",
   "name": "sklearnenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
